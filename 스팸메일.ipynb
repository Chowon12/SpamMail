{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsYoqnShvVzN",
        "outputId": "5b1e8ba7-6e0a-4865-cb09-0ab5e03d0174"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=4b265b8b8e48db982820884846efb96567d2e275f63547614111cca1d5128a27\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47qw4siwvS2H",
        "outputId": "4466377d-8bd0-4231-d1ed-79869948b206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "베스트 하이퍼 파라미터: {'alpha': 0.01}\n",
            "베스트 하이퍼 파라미터 일 때 정확도: 0.89\n",
            "테스트세트에서의 정확도: 0.90\n",
            "실제 값: talk.politics.misc, 예측 값: talk.politics.misc\n",
            "실제 값: comp.sys.mac.hardware, 예측 값: comp.sys.mac.hardware\n",
            "실제 값: sci.crypt, 예측 값: sci.crypt\n",
            "실제 값: talk.politics.guns, 예측 값: talk.politics.guns\n",
            "실제 값: alt.atheism, 예측 값: alt.atheism\n",
            "실제 값: comp.windows.x, 예측 값: comp.windows.x\n",
            "실제 값: sci.electronics, 예측 값: misc.forsale\n",
            "실제 값: comp.sys.mac.hardware, 예측 값: comp.sys.mac.hardware\n",
            "실제 값: sci.space, 예측 값: sci.space\n",
            "실제 값: talk.politics.guns, 예측 값: talk.politics.guns\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import numpy as np\n",
        "#받은 데이터들을 행렬로써 이용할 것이기에 행렬 연산을 용이하게 하는 numpy사용\n",
        "\n",
        "# 분류용 샘플 데이터 불러오기\n",
        "#문자열 데이터를 가져오는 출처가 fetch_20newsgroups()인 것이다. 다른 데아터를 가져 올 수도 있다.\n",
        "news = fetch_20newsgroups()\n",
        "X, y, labels = news.data, news.target, news.target_names\n",
        "\n",
        "# 학습/테스트 데이터셋 분할\n",
        "#train_test_split은 학습 모듈과 테스트 데이터를 나누는 함수이다. \n",
        "#X, y 2개의 데이터가 주어지면 X_train, X_test, y_train, y_test의 4개의 결과값이 나타난다. \n",
        "#test_size는 test와 train의 비율을 나타낸다. 0.3일 경우 테스트데이터는 전체 데이터의 30%이다.\n",
        "#random_state는 0일 경우 테스트 데이터가 고정되어 나타나고 1일 경우 테스트 데이터가 유동적으로 바뀌어 나타난다.\n",
        "#stratify는 Label Set인 y가 25%의 0과 75%의 1로 이루어진 Binary Set일 때, stratify=y로 설정하면 나누어진 데이터셋들도 0과 1을 각각 25%, 75%로 유지한 채 분할된다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
        "\n",
        "# 데이터 전처리(벡터화)\n",
        "#CountVectorizer()는 데이터 내 문자열들을 토큰화하여 나타내고 같은 토큰이 나타난 횟수도 나타내어 준다.\n",
        "#TfidfTransformer()는 CountVectorizer()와 달리 단어의 중요도에 따라 가중치를 주기 위한 함수이다. \n",
        "#CountVectorizer()는 토큰의 출현횟수를 나타내는데에 반해 TfidfTransformer()는 데이터 내의 토큰의 출현 비율을 나타내기 때문에 중요도를 파악할 수 있다. \n",
        "vectorizer = CountVectorizer()\n",
        "tfid = TfidfTransformer()\n",
        "\n",
        "#fit은 최대,최소,평균,분산 등의 scaling에 필요한 정보를 파악하는 용도의 함수이며 transform은 실제로 그 파악한 정보를 통해 데이터셋의 값을 변환시키는 함수이다. \n",
        "#fit_transform은 이 둘을 동시에 실행시키는 함수이다. 그러므로 테스트 데이터에는 학습에 영향을 주지 않도록 fit을 사용하지 않고 학습 데이터에만 fit명령어를 포함시킨다.\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "X_train_tfid = tfid.fit_transform(X_train_vec)\n",
        "X_test_tfid = tfid.transform(X_test_vec)\n",
        "\n",
        "# 다중분류 나이브 베이브 + 그리드서치로 모델 학습\n",
        "#np.linspace는 구간 시작점, 구간 끝점, 구간 내 숫자 개수를 받는다 0.01부터 1까지 100개의 숫자로 나타낸 것이다. \n",
        "#GridSearchCV는 하이퍼파라미터를 학습을 하고 측정을 하면서 최적화된 파라미터를 알려준다. \n",
        "#param_grid는 사용될 파라미터를 딕셔너리 형태로 만들어서 넣는다. scoring 은 파라미터에 대한 평가 방식에 해당한다.accuracy를 넣어 정확성을 평가한다.\n",
        "#cv는 교차 검증에서 몇개로 분할되는지 지정한다. n_jobs는 매개 변수를 사용하여 사용할 코어 수를 지정할 수 있다. 사용하는 CPU 코어 개수에 비례해서 속도도 빨라진다.\n",
        "nb = MultinomialNB()\n",
        "param_grid = [{'alpha': np.linspace(0.01, 1, 100)}]\n",
        "gs = GridSearchCV(estimator=nb, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "gs.fit(X_train_tfid, y_train)\n",
        "\n",
        "# 그리드서치 학습 결과 출력\n",
        "print('베스트 하이퍼 파라미터: {0}'.format(gs.best_params_))\n",
        "print('베스트 하이퍼 파라미터 일 때 정확도: {0:.2f}'.format(gs.best_score_))\n",
        "\n",
        "# 최적화 모델 추출\n",
        "model = gs.best_estimator_\n",
        "\n",
        "# 테스트세트 정확도 출력\n",
        "score = model.score(X_test_tfid, y_test)\n",
        "print('테스트세트에서의 정확도: {0:.2f}'.format(score))\n",
        "\n",
        "# 테스트세트 예측 결과 샘플 출력\n",
        "predicted_y = model.predict(X_test_tfid)\n",
        "for i in range(10):\n",
        "    print('실제 값: {0}, 예측 값: {1}'.format(labels[y_test[i]], labels[predicted_y[i]]))"
      ]
    }
  ]
}